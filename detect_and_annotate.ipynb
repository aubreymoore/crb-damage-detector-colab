{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq7VagPq/TK0cZD7rERWri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubreymoore/crb-damage-detector-colab/blob/main/detect_and_annotate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Colab Jupyter is still in development and may change a lot or even fail.\n",
        "\n",
        "If you have any problems, questions, or suggestions please contact me.\n",
        "\n",
        "Aubrey Moore (aubreymoore2013@gmail.com)"
      ],
      "metadata": {
        "id": "li0J-oJK77OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a timer for each cell\n",
        "%pip install ipython-autotime -q\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "GJUTRUbHYhRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# detect_and_annotate.ipynb\n",
        "\n",
        "NOTE: The following documentation is already slightly out of date.\n",
        "Please visit https://github.com/aubreymoore/crb-damage-detector-colab before running this notebook for the first time.\n",
        "\n",
        "This Colab Jupyter notebook runs a custom YOLOv8 object detector which scans images to find three object classes: live coconut palms, dead coconut palms and v-shaped cuts symptomatic of damage caused by coconut rhinoceros beetle, *Oryctes rhinoceros*.\n",
        "\n",
        "IMPORTANT: Shortly after the MAIN PROGRAM section begins executing, a BROWSE button will appear below the active cell to allow you to upload single file of input data from your loacal machine to Colab.\n",
        "\n",
        "**Note that Colab will just sit there and not do anything until you have entered a path to a test file of URLs or a ZIP file of images on your local machine.** [Click here to scroll down to the \"Browser\" button.](#scrollTo=5zSjfTXvIv2q&line=1&uniqifier=1)\n",
        "\n",
        "You may choose between 2 options:\n",
        "* A TEXT file (\\*.txt) containing URLs for images to be scanned. One URL per line. (This is the most efficient option.)\n",
        "* A ZIP file (\\*.zip) containing images to be scanned.\n",
        "\n",
        "\n",
        "Test data are available in a companion GitHub repository at https://github.com/aubreymoore/crb-damage-detector-colab. To use the test data, download it to your local computer it as a [ZIP file](https://github.com/aubreymoore/crb-damage-detector-colab/archive/refs/heads/main.zip) and unzip it. If you have **git** installed, you can clone the repo as an alternative. The TEXT file or ZIP file to be uploaded to Colab will be found in the repository's **data** folder.\n",
        "\n",
        "To scan images, select **Runtime | Run all** on the main menu.\n",
        "Results will be in a temporary OUTPUT folder which you can access using the **File browser** in the left Colab panel.\n",
        "\n",
        "When image scanning is complete, the OUTPUT folder will be compressed into a single ZIP file and automatically downloaded to your computer.\n",
        "\n",
        "### TODO\n",
        "\n",
        "- [ finished 2024-10-19] Reduce size of images in the companion GH repo to max dimension of 960px\n",
        "- [ ] Copy current trained model to companion GH repo\n",
        "- [ ] Copy this Jupyter notebook to companion GH repo\n",
        "- [ ] Add confidence values to bounding box labels.\n",
        "- [ ] Add database to OUTPUT folder\n",
        "- [ ] Extract GPS coordinates from image files\n",
        "- [ ] Figure out how to use URLs to access images stored on OneDrive (Sharepoint)"
      ],
      "metadata": {
        "id": "EUB3xquwb6sI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell contains a link to text file which contains a list of image files to be scanned.\n",
        "\n",
        "For example,\n",
        "```https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/data/urls.txt``` links to a file which contains:\n",
        "```\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_0532.JPG?raw=true\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_0671.JPG?raw=true\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_06XX.JPG?raw=true\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_0695.JPG?raw=true\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_0704.JPG?raw=true\n",
        "https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/images/IMG_0713.JPG?raw=true\n",
        "```\n",
        "Edit the following so that the url points to your own data, then press ```Run All``` near the top of this page, and ignore the warning."
      ],
      "metadata": {
        "id": "SDnuC4tAuvN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Import Images to be Scanned for CRB Damage\n",
        "\n",
        "This notebook currently uses a single parameter named INPUT_DATA_URL which is  a hyperlink  that determines which images are imported to be scanned for CRB damage. INPUT_DATA_URL points to **a text file containing a list of hyperlinks to images** or **a zip file containing the actual images**.\n",
        "\n",
        "#### Text file example\n",
        "Here is a link to a text file which points to a list of 5 images of coconut palm images from from Vanuatu provided by Sulav Paudel at AgResearch New Zealand.\n",
        "\n",
        "```\n",
        "INPUT_DATA_URL =  'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/Vanuatu.txt'\n",
        "````\n",
        "\n",
        "[View text file contents.](https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/Vanuatu.txt)\n",
        "\n",
        "#### Zip file example\n",
        "Here is an example of a zip file containing 3 images of coconut palms from Maui provided by  Nicole Ferguson at Hawaii Department of Agriculture.\n",
        "\n",
        "```\n",
        "INPUT_DATA_URL = 'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/vcuts_maui.zip'\n",
        "````\n",
        "\n",
        "[Download the zip file to your computer.](https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/vcuts_maui.zip)\n"
      ],
      "metadata": {
        "id": "-mttnJKM5Lx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  uncomment the following line to scan images in listed in Vanuatu.txt\n",
        "INPUT_DATA_URL = 'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/Vanuatu.txt'\n",
        "# INPUT_DATA_URL = 'https://aubreymoore.github.io/CRB-FIDL/image-list.txt'\n",
        "\n",
        "# uncomment the following line to scan images in vcuts_maui.zip\n",
        "# INPUT_DATA_URL = 'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/vcuts_maui.zip'"
      ],
      "metadata": {
        "id": "d38obFdBsWut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Python packages which are not preinstalled by Colab"
      ],
      "metadata": {
        "id": "7Rp6VisrdfNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AggzUm3SRJFO"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics -q\n",
        "%pip install supervision -q\n",
        "%pip install imutils -q\n",
        "%pip install icecream -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules"
      ],
      "metadata": {
        "id": "l0Uuj0JCi5Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import imutils\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "from skimage import io\n",
        "from icecream import ic\n",
        "from google.colab import files\n",
        "# ultralytics.checks()"
      ],
      "metadata": {
        "id": "U1cExUvHRlTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions"
      ],
      "metadata": {
        "id": "mV6zIMn0ZRGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_from_url(url):\n",
        "  \"\"\"\n",
        "  Downloads a text file from a URL and returns a list of its lines.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Download the file\n",
        "    !wget -q -O temp.txt {url}\n",
        "    # Read the lines into a list\n",
        "    with open('temp.txt', 'r') as f:\n",
        "      lines = f.read().splitlines()\n",
        "    # Clean up the temporary file\n",
        "    os.remove('temp.txt')\n",
        "    return lines\n",
        "  except Exception as e:\n",
        "    print(f\"Error downloading or reading file from {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# # Example usage (replace with actual URL)\n",
        "# url = 'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/data/urls.txt'\n",
        "# my_list = get_list_from_url(url)\n",
        "# if my_list:\n",
        "#   print(\"List created from URL:\")\n",
        "#   print(my_list)\n",
        "# else:\n",
        "#   print(\"Failed to create list from URL.\")"
      ],
      "metadata": {
        "id": "CS3etxbCq5dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_model_weights():\n",
        "  '''\n",
        "  Upload model weights from GitHub repo to **weights.pt** only if this file does not already exist.\n",
        "  '''\n",
        "  !wget -nc https://github.com/aubreymoore/code-for-CRB-damage-ai/raw/refs/heads/main/models/3class/train5/weights/best.pt -O weights.pt\n",
        "\n",
        "# upload_model_weights()"
      ],
      "metadata": {
        "id": "7Yc80WosFV0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_weights():\n",
        "  model = YOLO('weights.pt')"
      ],
      "metadata": {
        "id": "IN7dkUz24841"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_input_folder():\n",
        "  if not os.path.exists('INPUT'):\n",
        "    os.makedirs('INPUT')\n",
        "\n",
        "# create_input_folder()"
      ],
      "metadata": {
        "id": "TEW_0vwRZWEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_folder():\n",
        "  if not os.path.exists('OUTPUT'):\n",
        "    os.makedirs('OUTPUT')\n",
        "\n",
        "# create_output_folder()"
      ],
      "metadata": {
        "id": "OH8-tflD8taN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_garbage_disposal():\n",
        "  '''\n",
        "  Delete any data files left over from the last run.\n",
        "  '''\n",
        "  shutil.rmtree('INPUT', ignore_errors=True)\n",
        "  shutil.rmtree('OUTPUT', ignore_errors=True)\n",
        "  shutil.rmtree('sample_data', ignore_errors=True)\n",
        "\n",
        "  try:\n",
        "    os.remove('weights.pt')\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "# run_garbage_disposal()"
      ],
      "metadata": {
        "id": "N5Bb4M-9xLUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_unpack_zip_or_txt():\n",
        "  '''\n",
        "  Upload images (*.zip) or list of URLs (*.txt)\n",
        "  '''\n",
        "  uploaded = files.upload(target_dir='INPUT')\n",
        "  filename = list(uploaded.keys())[0]\n",
        "\n",
        "  urls = None\n",
        "  image_file_dir = None\n",
        "\n",
        "  if filename.endswith('.txt'):\n",
        "    input_mode = 'text'\n",
        "    with open(filename, 'r') as f:\n",
        "      urls = f.read().splitlines()\n",
        "  elif filename.endswith('.zip'):\n",
        "    input_mode = 'zip'\n",
        "    !unzip -q $filename -d INPUT\n",
        "    image_file_dir = f'INPUT/{filename}'.replace('.zip', '')\n",
        "    ic(image_file_dir)\n",
        "  else:\n",
        "    raise ValueError('INPUT file must be *.txt or *.zip.')\n",
        "  return input_mode, urls, image_file_dir\n",
        "\n",
        "# input_mode, urls, image_file_dir = upload_and_unpack_zip_or_txt()\n",
        "# ic(input_mode)\n",
        "# ic(urls)\n",
        "# ic(image_file_dir)"
      ],
      "metadata": {
        "id": "7PC5mvkBasff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_file_list():\n",
        "  return glob.glob(f'INPUT/**/*', recursive=True)\n",
        "\n",
        "# get_input_file_list()"
      ],
      "metadata": {
        "id": "GgC0yLmO7DFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(image, model, box_annotator, label_annotator, csv_sink):\n",
        "  '''\n",
        "  detect objects in an image\n",
        "  returns detections and an annotated image\n",
        "  '''\n",
        "  results = model(image)[0]\n",
        "  detections = sv.Detections.from_ultralytics(results)\n",
        "  # ic(detections)\n",
        "  annotated_image = box_annotator.annotate(image, detections=detections)\n",
        "  labels = [f\"{model.model.names[class_id]} {confidence:.2f}\" for class_id, confidence in zip(detections.class_id, detections.confidence)]\n",
        "  annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
        "  return detections, annotated_image\n",
        "\n",
        "# csv_sink = sv.CSVSink('detections.csv')\n",
        "# csv_sink.open()\n",
        "\n",
        "# upload_model_weights()\n",
        "# model = YOLO('weights.pt')\n",
        "# box_annotator = sv.BoxAnnotator()\n",
        "# label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# url = 'https://github.com/aubreymoore/crb-damage-detector-colab/blob/main/data/Vanuatu_July_2022_Sulav/resized-images/IMG_0532.JPG?raw=true'\n",
        "# image = imutils.url_to_image(url)\n",
        "# detections, annotated_image = detect_objects(image, model, box_annotator, label_annotator, csv_sink)\n",
        "# ic(detections)\n",
        "# sv.plot_image(annotated_image)\n",
        "\n",
        "# custom_data = {'url': url}\n",
        "# csv_sink.append(detections, custom_data)\n",
        "\n",
        "# csv_sink.close()"
      ],
      "metadata": {
        "id": "DIMCMtn5va3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def download_and_unzip(url, output_dir):\n",
        "  \"\"\"\n",
        "  Downloads a zip file from a URL and unzips it to a specified directory.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the zip file.\n",
        "    output_dir: The directory to extract the contents to.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "  local_zip_path = os.path.join(output_dir, url.split('/')[-1])\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(local_zip_path, 'wb') as f:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        f.write(chunk)\n",
        "\n",
        "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(output_dir)\n",
        "\n",
        "    os.remove(local_zip_path) # Clean up the downloaded zip file\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading the file: {e}\")\n",
        "  except zipfile.BadZipFile:\n",
        "    print(\"Error: The downloaded file is not a valid zip file.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Example usage (uncomment to test)\n",
        "# zip_url = 'https://github.com/aubreymoore/crb-damage-detector-colab/raw/refs/heads/main/vcuts_maui.zip'\n",
        "# output_directory = 'downloaded_zip_contents'\n",
        "# download_and_unzip(zip_url, output_directory)"
      ],
      "metadata": {
        "id": "iMQgLN6pGOlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN PROGRAM"
      ],
      "metadata": {
        "id": "uOi1eL7K7Paw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear data files from previous run\n",
        "run_garbage_disposal()\n",
        "\n",
        "create_input_folder()\n",
        "create_output_folder()\n",
        "\n",
        "# Upload images or list of URLs\n",
        "# input_mode, urls, image_file_dir = upload_and_unpack_zip_or_txt()\n",
        "\n",
        "\n",
        "# Upload weights from trained model and load them\n",
        "upload_model_weights()\n",
        "model = YOLO('weights.pt')\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "csv_sink = sv.CSVSink('OUTPUT/detections.csv')\n",
        "csv_sink.open()\n",
        "\n",
        "# Scan images\n",
        "if INPUT_DATA_URL[-4:].lower() == '.txt':\n",
        "  urls = get_list_from_url(INPUT_DATA_URL)\n",
        "  ic(urls)\n",
        "  for url in urls:\n",
        "    try:\n",
        "      image = imutils.url_to_image(url)\n",
        "      detections, annotated_image = detect_objects(image, model, box_annotator, label_annotator, csv_sink)\n",
        "      csv_sink.append(\n",
        "          detections,\n",
        "          custom_data={'image_h': image.shape[0], 'image_w': image.shape[1], 'source': url}\n",
        "      )\n",
        "\n",
        "      # Extract filename from URL\n",
        "      filename = url.split('/')[-1]\n",
        "      pos = filename.find('?')\n",
        "      if pos >= 0:\n",
        "        filename = filename[:pos]\n",
        "      output_path = f'OUTPUT/{filename}'.replace('.', '_annotated.')\n",
        "      ic(output_path)\n",
        "      os.makedirs(os.path.dirname(output_path), exist_ok = True)\n",
        "      cv2.imwrite(output_path, annotated_image)\n",
        "    except:\n",
        "      print(f'Error processing {url}')\n",
        "    continue\n",
        "\n",
        "if INPUT_DATA_URL[-4:].lower() == '.zip':\n",
        "  download_and_unzip(url=INPUT_DATA_URL, output_dir='INPUT')\n",
        "  input_file_list = get_input_file_list()\n",
        "  ic(input_file_list)\n",
        "  for image_path in input_file_list:\n",
        "    ic(image_path)\n",
        "    try:\n",
        "      image = cv2.imread(image_path)\n",
        "      detections, annotated_image = detect_objects(image, model, box_annotator, label_annotator, csv_sink)\n",
        "      csv_sink.append(\n",
        "          detections,\n",
        "          custom_data={'image_h': image.shape[0], 'image_w': image.shape[1], 'source': image_path}\n",
        "      )\n",
        "\n",
        "      filename = os.path.basename(image_path)\n",
        "      output_path = f'OUTPUT/{filename}'.replace('.', '_annotated.')\n",
        "      os.makedirs(os.path.dirname(output_path), exist_ok = True)\n",
        "      result = cv2.imwrite(output_path, annotated_image)\n",
        "    except:\n",
        "      print(f'Error processing {image_path}')\n",
        "    continue\n",
        "\n",
        "csv_sink.close()"
      ],
      "metadata": {
        "id": "kGRopezOreIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please click on the Browse buttom when it appears above this cell."
      ],
      "metadata": {
        "id": "5zSjfTXvIv2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download OUTPUT folder as a ZIP file"
      ],
      "metadata": {
        "id": "NTYyOn8QztJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r OUTPUT.zip OUTPUT"
      ],
      "metadata": {
        "id": "l8tPKEwW4JPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"OUTPUT.zip\")"
      ],
      "metadata": {
        "id": "ODvR3p_8zG1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINISHED\n",
        "If everything worked as intended, you should find a file named **OUTPUT.zip** in your Downloads folder. Unzip this file to see results."
      ],
      "metadata": {
        "id": "LOCD7_KCdMh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('FINISHED')"
      ],
      "metadata": {
        "id": "dfWKUVoS2b92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}